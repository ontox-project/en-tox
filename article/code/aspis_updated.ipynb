{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow for relationship extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df2cc51-c411-46b0-ae9f-5cf3a6c61a84",
   "metadata": {},
   "source": [
    "# Literature extraction from PubMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b44bac6f-9c24-40c7-bb85-6c9963372b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-21 13:43:37 hujupyterhub10 metapub.config[12544] WARNING NCBI_API_KEY was not set.\n"
     ]
    }
   ],
   "source": [
    "# library imports \n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "from csv import DictReader\n",
    "\n",
    "from metapub import PubMedFetcher # for Entrez query\n",
    "from Bio.Entrez import efetch # for Entrez query\n",
    "from Bio import Entrez # for Entrez query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8de26486-ed59-4e4a-b0b6-449ebe6db674",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"en_tox\" # model selection\n",
    "Entrez.email = 'A.N.Other@example.com' # replace with own email\n",
    "Entrez.api_key = \"xxx\" # replace with own key\n",
    "# select input data (chemical list with chemical names):\n",
    "datafile = \"ChemicalList.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve PMIDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \" AND toxic* AND (human OR Animals, Laboratory OR Disease Models, Animal)\"\n",
    "chemical_list = pd.read_csv(datafile)\n",
    "retmax = 100 # Maximum number of articles to retrieve\n",
    "fetch = PubMedFetcher()\n",
    "aspis = {}\n",
    "for chemical in chemical_list[\"Compound Name\"]:\n",
    "    aspis[\"pmids\"] = fetch.pmids_for_query(chemical + query, retmax=retmax)\n",
    "\n",
    "with open(\"data/aspis_abstracts_updated.csv\", \"w\") as file:\n",
    "    csvwriter = csv.DictWriter(file, aspis.keys())\n",
    "    csvwriter.writeheader()\n",
    "    csvwriter.writerows(aspis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbde0b2f-f695-4d08-893e-15ec7f225422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "df_aspis =pd.read_csv(\"data/aspis_abstracts_updated.csv\")\n",
    "df_aspis['pmids'] = df_aspis['pmids'].apply(literal_eval)\n",
    "df_aspis = df_aspis.explode('pmids', ignore_index = True)\n",
    "# Remove duplicates (a same article can be linked to multiple chemicals)\n",
    "df_aspis_nodup = df_aspis.drop_duplicates(subset=['pmids'])\n",
    "df_aspis_nodup\n",
    "\n",
    "aspis_nodup = df_aspis_nodup.to_dict('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a9f3dd-b6a4-410d-aa47-77d07270a74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch abstracts\n",
    "t0 = time.time()\n",
    "\n",
    "for d in aspis_nodup:\n",
    "    if str(d[\"pmids\"])=='nan':\n",
    "        d[\"abstract\"] = \"\"\n",
    "    else:\n",
    "        try:\n",
    "            d[\"abstract\"] = utils.fetch_abstract(d[\"pmids\"])\n",
    "        except HTTPError:\n",
    "            d[\"abstract\"] = \"HTTPError\"\n",
    "            print(\"HTTPerror\")\n",
    "   \n",
    "t1 = time.time()\n",
    "\n",
    "print(\"Time elapsed:\" + str(t1-t0))\n",
    "\n",
    "# write abstracts to .csv file\n",
    "aspis_nodup = list(aspis_nodup)\n",
    "keys = aspis_nodup[0].keys()\n",
    "\n",
    "with open(\"data/aspis_abstracts_text_updated.csv\", \"w\") as file:\n",
    "    csvwriter = csv.DictWriter(file, keys)\n",
    "    csvwriter.writeheader()\n",
    "    csvwriter.writerows(aspis_nodup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3c5bb2a8-5a76-41e2-a1a7-9e95b3bf94a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aspis = pd.read_csv(\"data/aspis_abstracts_text_updated.csv\")\n",
    "# Convert to right type\n",
    "aspis['pmids'] = aspis['pmids'].astype('Int64')\n",
    "aspis['abstract'] = aspis['abstract'].astype('str')\n",
    "\n",
    "# Get lists of pmids and abstracts text for CREW workflow\n",
    "pmids = aspis['pmids'].tolist()\n",
    "abst = aspis['abstract'].tolist()\n",
    "\n",
    "# transpose to dict\n",
    "abstracts = dict(zip(pmids, abst))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc55fcea-8a3d-4ecb-a7f6-cf461399a803",
   "metadata": {},
   "source": [
    "# NLP on abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0da9de2-7a1d-460e-9f78-73d019a82912",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load spaCy models\n",
    "import spacy\n",
    "from spacy.matcher import DependencyMatcher\n",
    "from scispacy.abbreviation import AbbreviationDetector\n",
    "from spacy.pipeline import EntityRuler\n",
    "from scispacy.linking import EntityLinker\n",
    "import utils as utils\n",
    "nlp = spacy.load(\"en_tox\")\n",
    "\n",
    "# add abbreviation detector pipe to spaCy model\n",
    "nlp.add_pipe(\"abbreviation_detector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0295c455-2e10-4220-870c-e41921c3a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into sentences\n",
    "df = utils.get_df_pmid_sents(nlp, abstracts)\n",
    "#df.to_csv(\"data/aspis_sentences_updated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d430bf8-7223-4b5a-8676-5adcbfa2c822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify sentences with entities of interest: 2 phenotypes, or a phenotype and a chemical\n",
    "#df = pd.read_csv(\"data/aspis_sentences_updated.csv\")\n",
    "df_pheno = utils.get_df_relations(nlp,\"PHENOTYPE\",\"PHENOTYPE\", df)\n",
    "df_pheno.to_csv(\"data/aspis_relations_pheno_updated.csv\")\n",
    "df_chem = utils.get_df_relations(nlp,\"COMPOUND\",\"PHENOTYPE\", df)\n",
    "df_chem.to_csv(\"data/aspis_relations_chem_updated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "250705ee-6406-4551-961f-7d011e93a8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of causal verbs to use in dependency matcher\n",
    "causal_verbs = ['increase', 'produce', 'cause', \n",
    "                'induce', 'generate', 'effect', \n",
    "                'provoke', 'arouse', 'elicit', 'lead', 'trigger',\n",
    "                'derive', 'associate', 'relate', 'link', \n",
    "                'stem', 'originate', 'lead', 'bring', \n",
    "                'result', 'inhibit', 'elevate', 'diminish']\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationships between phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8eb94bb2-4816-4d6d-bc20-7d431f6522ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run dependency matcher\n",
    "matcher_pheno = utils.dependency_matcher(nlp, \"PHENOTYPE\", \"PHENOTYPE\")\n",
    "df_pheno = pd.read_csv(\"data/aspis_relations_pheno_updated.csv\")\n",
    "df_pheno = utils.get_df_dependencyMatcher(nlp, df_pheno, matcher_pheno, causal_verbs)\n",
    "# transform list elements to rows\n",
    "df_pheno = df_pheno.explode(['Verb Match','Cause Match', 'Effect Match'])\n",
    "# save df to csv\n",
    "df_pheno.to_csv(\"data/aspis_en_tox_pheno_pheno_updated.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationships between compounds and phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3312f6f8-cd5b-45cc-ad4b-702bd1195c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher_chem = utils.dependency_matcher(nlp, \"COMPOUND\", \"PHENOTYPE\")\n",
    "df_chem = pd.read_csv(\"data/aspis_relations_chem_updated.csv\")\n",
    "df_chem = utils.get_df_dependencyMatcher(nlp, df_chem, matcher_chem, causal_verbs)\n",
    "# transform list elements to rows\n",
    "df_chem = df_chem.explode(['Verb Match','Cause Match', 'Effect Match'])\n",
    "# save df to csv\n",
    "df_chem.to_csv(\"adata/spis_en_tox_compound_pheno_updated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2329583b-f86a-4f23-b8ec-f0b06bb5b8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only sentences with a match \n",
    "df_pheno = pd.read_csv(\"aspis_en_tox_pheno_pheno_updated.csv\")\n",
    "df_pheno = pd.DataFrame(df_pheno.loc[df_pheno['Has Match'] == True])\n",
    "# Remove identical phenotypes\n",
    "df_pheno = pd.DataFrame(df_pheno.loc[df_pheno['Cause Match'] != df_pheno['Effect Match']])\n",
    "df_pheno.to_csv(\"aspis_en_tox_pheno_match_updated.csv\")\n",
    "\n",
    "df_chem = pd.read_csv(\"aspis_en_tox_compound_pheno_updated.csv\")\n",
    "df_chem = pd.DataFrame(df_chem.loc[df_chem['Has Match'] == True])\n",
    "# Remove identical phenotypes\n",
    "df_chem = pd.DataFrame(df_chem.loc[df_chem['Cause Match'] != df_chem['Effect Match']])\n",
    "df_chem.to_csv(\"aspis_en_tox_compound_match_updated.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c38df6-74f0-4562-8305-ffb9c7867f39",
   "metadata": {},
   "source": [
    "# Load data to neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b084f75-2e24-4dd6-9ca4-08b5ac398275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import to personal neo4j instance, without factors\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Database Credentials\n",
    "uri = \"bolt://localhost:7687\" # replace with own local db\n",
    "userName = \"neo4j\" # replace with own username\n",
    "password = \"xx\" # replace with own password\n",
    "\n",
    "# Connect to the neo4j database server\n",
    "graphDB_Driver  = GraphDatabase.driver(uri, auth=(userName, password))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fee7130-832f-4ae8-9d8a-2b91ee875276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rel_neo4j_cp(row, cause, effect):\n",
    "    # Verify that nodes and relationships do not exist, otherwise create them (MERGE)\n",
    "    cqlCreate = \"\"\"MERGE (n1:%s { name: \"%s\"})\n",
    "    MERGE (n2:%s { name: \"%s\"})\n",
    "    MERGE (n1)-[:%s {PMID:%s}]-(n2)\"\"\" %(cause,row[\"Cause Match\"],effect,row[\"Effect Match\"],row[\"Verb Match\"],row[\"Pmid\"])\n",
    "    return cqlCreate\n",
    "\n",
    "def create_rel_neo4j_pp(row, cause, effect):\n",
    "    # Verify that nodes and relationships do not exist, otherwise create them (MERGE)\n",
    "    cqlCreate = \"\"\"MERGE (n1:%s {name: \"%s\"})\n",
    "    MERGE (n2:%s { name: \"%s\"})\n",
    "    MERGE (n1)-[:%s {PMID:%s}]-(n2)\"\"\" %(cause,row[\"Cause Match\"],effect,row[\"Effect Match\"],row[\"Verb Match\"],row[\"Pmid\"])\n",
    "    return cqlCreate\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('neo4j')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "9568dcf2ae80fe23a24d65c11accca08250fe6401cb4b2cda91811bfc4c2b32f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
